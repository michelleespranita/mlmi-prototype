{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:44:09.368542: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get weights from pre-trained Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:45:07.553734: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "keras_DNN = load_model(\"CF_Mortality.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 48)                3120      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 48)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 16)                784       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,866\n",
      "Trainable params: 32,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_DNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_DNN_weights = keras_DNN.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct Keras model in PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef DNN_Simple(shape):\\n    X_in = Input(shape=(shape,))\\n    H2 = Dense(128, activation='relu', kernel_regularizer=l2(5e-4))(X_in)\\n    H3 = Dropout(0.5)(H2)\\n    H4 = Dense(64, activation='relu', kernel_regularizer=l2(5e-4))(H3)\\n    H5 = Dropout(0.2)(H4)\\n    H6 = Dense(64, activation='relu', kernel_regularizer=l2(5e-4))(H5)\\n    H7 = Dropout(0.2)(H6)\\n    H8 = Dense(48, activation='relu', kernel_regularizer=l2(5e-4))(H7)\\n    H9 = Dropout(0.2)(H8)\\n    H10 = Dense(16, activation='relu', kernel_regularizer=l2(5e-4))(H9)\\n    H11 = Dropout(0.5)(H10)\\n    Y = Dense(3, activation='softmax')(H11)\\n    model = Model(inputs=X_in, outputs=Y)\\n    model.compile(optimizer=optimizers.Adam(decay=0.01),loss='categorical_crossentropy'\\n                  ,metrics=['accuracy']) \\n    return model\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def DNN_Simple(shape):\n",
    "    X_in = Input(shape=(shape,))\n",
    "    H2 = Dense(128, activation='relu', kernel_regularizer=l2(5e-4))(X_in)\n",
    "    H3 = Dropout(0.5)(H2)\n",
    "    H4 = Dense(64, activation='relu', kernel_regularizer=l2(5e-4))(H3)\n",
    "    H5 = Dropout(0.2)(H4)\n",
    "    H6 = Dense(64, activation='relu', kernel_regularizer=l2(5e-4))(H5)\n",
    "    H7 = Dropout(0.2)(H6)\n",
    "    H8 = Dense(48, activation='relu', kernel_regularizer=l2(5e-4))(H7)\n",
    "    H9 = Dropout(0.2)(H8)\n",
    "    H10 = Dense(16, activation='relu', kernel_regularizer=l2(5e-4))(H9)\n",
    "    H11 = Dropout(0.5)(H10)\n",
    "    Y = Dense(3, activation='softmax')(H11)\n",
    "    model = Model(inputs=X_in, outputs=Y)\n",
    "    model.compile(optimizer=optimizers.Adam(decay=0.01),loss='categorical_crossentropy'\n",
    "                  ,metrics=['accuracy']) \n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 48)\n",
    "        self.fc5 = nn.Linear(48, 16)\n",
    "        self.output = nn.Linear(16, 2)\n",
    "        \n",
    "        self.dropout_50 = nn.Dropout(0.5)\n",
    "        self.dropout_20 = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout_50(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout_20(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout_20(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout_20(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout_50(x)\n",
    "        return F.softmax(self.output(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer pre-trained weights from Keras model to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_DNN = DNN(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=48, bias=True)\n",
       "  (fc5): Linear(in_features=48, out_features=16, bias=True)\n",
       "  (output): Linear(in_features=16, out_features=2, bias=True)\n",
       "  (dropout_50): Dropout(p=0.5, inplace=False)\n",
       "  (dropout_20): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_DNN.fc1.weight.data = torch.from_numpy(np.transpose(keras_DNN_weights[0]))\n",
    "pytorch_DNN.fc1.bias.data = torch.from_numpy(keras_DNN_weights[1])\n",
    "pytorch_DNN.fc2.weight.data = torch.from_numpy(np.transpose(keras_DNN_weights[2]))\n",
    "pytorch_DNN.fc2.bias.data = torch.from_numpy(keras_DNN_weights[3])\n",
    "pytorch_DNN.fc3.weight.data = torch.from_numpy(np.transpose(keras_DNN_weights[4]))\n",
    "pytorch_DNN.fc3.bias.data = torch.from_numpy(keras_DNN_weights[5])\n",
    "pytorch_DNN.fc4.weight.data = torch.from_numpy(np.transpose(keras_DNN_weights[6]))\n",
    "pytorch_DNN.fc4.bias.data = torch.from_numpy(keras_DNN_weights[7])\n",
    "pytorch_DNN.fc5.weight.data = torch.from_numpy(np.transpose(keras_DNN_weights[8]))\n",
    "pytorch_DNN.fc5.bias.data = torch.from_numpy(keras_DNN_weights[9])\n",
    "pytorch_DNN.output.weight.data = torch.from_numpy(np.transpose(keras_DNN_weights[10]))\n",
    "pytorch_DNN.output.bias.data = torch.from_numpy(keras_DNN_weights[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if Keras and PyTorch models behave similarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=48, bias=True)\n",
       "  (fc5): Linear(in_features=48, out_features=16, bias=True)\n",
       "  (output): Linear(in_features=16, out_features=2, bias=True)\n",
       "  (dropout_50): Dropout(p=0.5, inplace=False)\n",
       "  (dropout_20): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_DNN.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.rand(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3444, 0.9813, 0.7785, 0.0401, 0.3178, 0.0788, 0.0755, 0.8693, 0.1432,\n",
       "        0.9060, 0.9657, 0.1413, 0.5917, 0.5230, 0.9480, 0.5470, 0.3413, 0.9207,\n",
       "        0.7817, 0.7178, 0.7958, 0.9180, 0.0037, 0.2990, 0.2454, 0.6125, 0.5545,\n",
       "        0.6472, 0.8791, 0.5012, 0.0671, 0.7632, 0.8862, 0.7937, 0.9149, 0.6799,\n",
       "        0.7679, 0.5965, 0.8130, 0.5568, 0.7320, 0.6051, 0.9923, 0.7988, 0.0129,\n",
       "        0.7642, 0.3316, 0.1957, 0.9704, 0.7133, 0.5589, 0.5751, 0.9515, 0.5327,\n",
       "        0.7401, 0.9360, 0.2170, 0.9183, 0.1435, 0.7323, 0.1798, 0.6054, 0.9977,\n",
       "        0.6405, 0.0051, 0.4881, 0.2498, 0.9334, 0.1217, 0.1179, 0.0584, 0.2180,\n",
       "        0.6156, 0.2785, 0.0810, 0.8296, 0.3665, 0.9396, 0.4603, 0.6959, 0.7657,\n",
       "        0.6067, 0.1079, 0.4412, 0.6775, 0.2643, 0.1774, 0.1865, 0.8165, 0.1248,\n",
       "        0.0606, 0.8652, 0.2587, 0.8120, 0.3374, 0.8718, 0.9300, 0.2189, 0.7270,\n",
       "        0.9533, 0.1167, 0.5172, 0.9277, 0.6798, 0.9896, 0.1638, 0.5077, 0.9047,\n",
       "        0.6243, 0.6280, 0.8183, 0.3287, 0.7978, 0.2390, 0.6630, 0.6689, 0.8449,\n",
       "        0.3937, 0.6241, 0.0741, 0.3868, 0.8988, 0.8302, 0.8232, 0.4215, 0.8584,\n",
       "        0.7517, 0.3925])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/nvtp62xj7_188hvgxm3r35hm0000gn/T/ipykernel_8348/3945986980.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(self.output(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9708, 0.0292], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_DNN(test_input.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_np = test_input.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34444815, 0.98134845, 0.7784901 , 0.04014856, 0.3177709 ,\n",
       "       0.0787943 , 0.0755015 , 0.86933136, 0.14321393, 0.906044  ,\n",
       "       0.96566004, 0.14130646, 0.5916648 , 0.52301526, 0.94802105,\n",
       "       0.54704887, 0.3413403 , 0.9207316 , 0.7817209 , 0.71782655,\n",
       "       0.795812  , 0.91804063, 0.00367725, 0.2990077 , 0.24542099,\n",
       "       0.612544  , 0.5544843 , 0.6472434 , 0.87913364, 0.50120884,\n",
       "       0.06712216, 0.7632213 , 0.88622284, 0.7936504 , 0.9148641 ,\n",
       "       0.6799495 , 0.76788527, 0.5964951 , 0.81298876, 0.55682194,\n",
       "       0.7319585 , 0.60513514, 0.9923075 , 0.79879034, 0.01287615,\n",
       "       0.7641729 , 0.33162028, 0.19571972, 0.9703503 , 0.7132627 ,\n",
       "       0.5589338 , 0.57507455, 0.95145875, 0.5327248 , 0.74010134,\n",
       "       0.93602276, 0.21703333, 0.91828215, 0.14354217, 0.7323243 ,\n",
       "       0.179784  , 0.605447  , 0.99767494, 0.6404511 , 0.00507313,\n",
       "       0.48806643, 0.24979359, 0.93336   , 0.12174898, 0.11792588,\n",
       "       0.05844009, 0.21797788, 0.61563385, 0.27853143, 0.08098823,\n",
       "       0.82955176, 0.36652935, 0.93955314, 0.46032202, 0.6959357 ,\n",
       "       0.7657392 , 0.60666317, 0.10790008, 0.44122905, 0.67750704,\n",
       "       0.26428145, 0.17736197, 0.18648636, 0.81652236, 0.12478924,\n",
       "       0.06061262, 0.8652224 , 0.25874698, 0.8120325 , 0.337363  ,\n",
       "       0.8717966 , 0.92998344, 0.218947  , 0.7269598 , 0.9532694 ,\n",
       "       0.1167447 , 0.51719254, 0.9276611 , 0.6797793 , 0.98961234,\n",
       "       0.16380787, 0.5077121 , 0.90474486, 0.624268  , 0.6279793 ,\n",
       "       0.8183193 , 0.32871008, 0.7977818 , 0.23904616, 0.6630274 ,\n",
       "       0.6689063 , 0.8449107 , 0.39367956, 0.62413996, 0.07408792,\n",
       "       0.38684   , 0.89878964, 0.8302077 , 0.8231639 , 0.42153466,\n",
       "       0.8583563 , 0.7517314 , 0.3924588 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.97076607, 0.02923388]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_DNN.predict(test_input_np.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cy/nvtp62xj7_188hvgxm3r35hm0000gn/T/ipykernel_3793/1240730703.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"matt_metadata_norm.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"matt_metadata_norm.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aim",
   "language": "python",
   "name": "aim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
