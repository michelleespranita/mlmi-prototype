{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eN_8aK75RmDQ"
   },
   "outputs": [],
   "source": [
    "# !pip install py7zr \n",
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install rouge-score\n",
    "# !pip install nltk\n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jvB3IEHNRsNY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 228k/228k [00:00<00:00, 450kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GxZP8nlRsJv"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model.embeddings.token_type_embeddings = nn.Embedding(3,768)\n",
    "# (num_modalities/num_token_types, hidden_size)\n",
    "# By default, num_modalities is 2\n",
    "# 768 is the dimension of the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xi530a9JRsHn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "img_embeddings = torch.from_numpy(np.random.rand(1,10,768)).float()\n",
    "tabular_embeddings=torch.from_numpy(np.random.rand(1,4,768)).float()\n",
    "radiomics_embeddings=torch.from_numpy(np.random.rand(1,3,768)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCr0JrSgRsFc"
   },
   "outputs": [],
   "source": [
    "random_embeddings=torch.cat([img_embeddings,tabular_embeddings,radiomics_embeddings],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZDCHHW_RsC0",
    "outputId": "d8f574ed-9c50-4e20-d702-9c2690bbe5e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5hHd6qGRr-A",
    "outputId": "2331409c-35a0-402d-fc53-c6db054518b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-1bb7ec631b9b>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_type_ids=torch.tensor(torch.cat([torch.zeros(1,10),torch.ones(1,4),torch.ones(1,3)*2],axis=-1),dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "token_type_ids=torch.tensor(torch.cat([torch.zeros(1,10),torch.ones(1,4),torch.ones(1,3)*2],axis=-1),dtype=torch.int32)\n",
    "position_ids=torch.tensor([range(17) for i in range(1)],dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcCag-u_Rrxd",
    "outputId": "a2759412-f45f-49f8-8764-d8f5b4572606"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4f_hgo78ScH",
    "outputId": "338f2cf4-6a62-4916-aeef-f46475a784bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids\n",
    "# position_ids: Sequence only within the modality\n",
    "# image: (0, ..., n_image)\n",
    "# tabular: (0, ..., n_tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KN8RqIgaSHGu"
   },
   "outputs": [],
   "source": [
    "output_embds=model(inputs_embeds=random_embeddings,position_ids=position_ids,token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ora0ihv3SHDV",
    "outputId": "4a013319-ae1c-48ee-a503-51e6dcf96b66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_embds.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDDTAcLsSLa_",
    "outputId": "a16fb632-d100-4ffb-bf37-65e5239d963b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1345,  0.1185, -0.7807,  ...,  0.9029, -0.7225, -1.8057],\n",
       "         [ 0.1493,  0.1543, -0.8277,  ...,  0.8729, -0.7316, -1.7966],\n",
       "         [ 0.1243,  0.1802, -0.8694,  ...,  0.8780, -0.7229, -1.8201],\n",
       "         ...,\n",
       "         [-1.1394, -0.1683, -1.0218,  ..., -0.0394, -0.9424, -1.1058],\n",
       "         [-0.9834, -0.1311, -1.0033,  ..., -0.0075, -1.0196, -1.1825],\n",
       "         [-0.9458, -0.0936, -1.1333,  ..., -0.0198, -1.0350, -1.0842]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_embds.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aim",
   "language": "python",
   "name": "aim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
